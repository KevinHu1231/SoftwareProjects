{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOVxQaS2g5Q0zGaoU47cmiS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"6T9xu8mpFzAO"},"outputs":[],"source":["!pip install voxelmorph "]},{"cell_type":"code","source":["# imports\n","import os, sys\n","\n","# third party imports\n","import numpy as np\n","import tensorflow as tf\n","assert tf.__version__.startswith('2.'),\n","import cv2"],"metadata":{"id":"1et-hYeJF8kI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# local imports\n","import voxelmorph as vxm\n","import neurite as ne"],"metadata":{"id":"zmUZRHvfGDG3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_images_from_folder(folder):\n","  images = None\n","  num_images = 0\n","  for filename in os.listdir(folder):\n","    img = cv2.imread(os.path.join(folder,filename))\n","    if img is not None:\n","      num_images+=1\n","      if images is None:\n","        images = img\n","      else:\n","        images = np.stack((images,img),axis=0) \n","  return images, num_images"],"metadata":{"id":"WZduH_2qGJwW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["images, num_images = load_images_from_folder(\"image_registration_data\", num_images)\n","x_train = images[:(int(0.8*num_images)),:,:,:]\n","x_val = images[(int(0.8*num_images)+1):,:,:,:]\n","print(\"Training Data Shape: \", x_train.shape())\n","print(\"Training Data Shape: \", x_val.shape())"],"metadata":{"id":"ul4dGfNXIHJ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nb_vis = 5\n","\n","# choose nb_vis sample indexes\n","idx = np.random.choice(x_train.shape[0], nb_vis, replace=False)\n","example_imgs = [f for f in x_train[idx, ...]]\n","\n","# plot\n","# ne.plot.slices(example_imgs, cmaps=['gray'], do_colorbars=True);"],"metadata":{"id":"cushXQb8LeF-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# normalize between [0, 1]\n","x_train = x_train.astype('float')/255\n","\n","# verify\n","print('training maximum value', x_train.max())"],"metadata":{"id":"cO9ozF_mNgXr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# re-visualize\n","example_imgs = [f for f in x_train[idx, ...]]\n","#plot\n","#ne.plot.slices(example_digits, cmaps=['gray'], do_colorbars=True);"],"metadata":{"id":"5D9omfk5NyKK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Images (2560 x 1440) (5*2^9 x 45*2^5)\n","# Try 32 first, no padding\n","\n","# Need to update to make input size a multiple of 2^N\n","#pad_amount = ((0, 0), (2,2), (2,2))\n","\n","# fix data\n","# x_train = np.pad(x_train, pad_amount, 'constant')"],"metadata":{"id":"D4hMYZg1N4jh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["CNN Model"],"metadata":{"id":"XLHC4cYXPajk"}},{"cell_type":"code","source":["# configure unet input shape (concatenation of moving and fixed images)\n","ndim = 3\n","unet_input_features = 2\n","inshape = (*x_train.shape[1:], unet_input_features)\n","\n","# configure unet features \n","nb_features = [\n","    [32, 32, 32, 32],   # encoder features\n","    [32, 32, 32, 32, 32, 16]  # decoder features\n","]\n","\n","# build model\n","unet = vxm.networks.Unet(inshape=inshape, nb_features=nb_features)"],"metadata":{"id":"doFRGvPSPdJ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('input shape: ', unet.input.shape)\n","print('output shape:', unet.output.shape)"],"metadata":{"id":"KrRnVV6tapbD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# transform the results into a flow field.\n","disp_tensor = tf.keras.layers.Conv2D(ndim, kernel_size=3, padding='same', name='disp')(unet.output)\n","\n","# check tensor shape\n","print('displacement tensor:', disp_tensor.shape)\n","\n","# using keras, we can easily form new models via tensor pointers\n","def_model = tf.keras.models.Model(unet.inputs, disp_tensor)"],"metadata":{"id":"N2Wgt4uHaqC5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# build transformer layer\n","spatial_transformer = vxm.layers.SpatialTransformer(name='transformer')\n","\n","# extract the first frame (i.e. the \"moving\" image) from unet input tensor\n","moving_image = tf.expand_dims(unet.input[..., 0], axis=-1)\n","\n","# warp the moving image with the transformer\n","moved_image_tensor = spatial_transformer([moving_image, disp_tensor])"],"metadata":{"id":"-3FfFClNa3bf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outputs = [moved_image_tensor, disp_tensor]\n","vxm_model = tf.keras.models.Model(inputs=unet.inputs, outputs=outputs)"],"metadata":{"id":"JuRsVeBTqCX_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# build model using VxmDense\n","inshape = x_train.shape[1:]\n","vxm_model = vxm.networks.VxmDense(inshape, nb_features, int_steps=0, src_feats=3, trg_feats=3)"],"metadata":{"id":"qQxDKBr_qFxL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('input shape: ', ', '.join([str(t.shape) for t in vxm_model.inputs]))\n","print('output shape:', ', '.join([str(t.shape) for t in vxm_model.outputs]))"],"metadata":{"id":"t6y_aOdPqJ0w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# voxelmorph has a variety of custom loss classes\n","losses = [vxm.losses.MSE().loss, vxm.losses.Grad('l2').loss]\n","\n","# usually, we have to balance the two losses by a hyper-parameter\n","lambda_param = 0.05\n","loss_weights = [1, lambda_param]"],"metadata":{"id":"Ng2QyMOkqSYf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vxm_model.compile(optimizer='Adam', loss=losses, loss_weights=loss_weights)"],"metadata":{"id":"Nlp5XQLtqTIT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def vxm_data_generator(x_data, batch_size=32):\n","    \"\"\"\n","    Generator that takes in data of size [N, H, W], and yields data for\n","    our custom vxm model. Note that we need to provide numpy data for each\n","    input, and each output.\n","\n","    inputs:  moving [bs, H, W, 1], fixed image [bs, H, W, 1]\n","    outputs: moved image [bs, H, W, 1], zero-gradient [bs, H, W, 2]\n","    \"\"\"\n","\n","    # preliminary sizing\n","    vol_shape = x_data.shape[1:] # extract data shape\n","    ndims = len(vol_shape)\n","    \n","    # prepare a zero array the size of the deformation\n","    # we'll explain this below\n","    zero_phi = np.zeros([batch_size, *vol_shape, ndims])\n","    \n","    while True:\n","        # prepare inputs:\n","        # images need to be of the size [batch_size, H, W, 1]\n","        idx1 = np.random.randint(0, x_data.shape[0], size=batch_size)\n","        moving_images = x_data[idx1, ..., np.newaxis]\n","        idx2 = np.random.randint(0, x_data.shape[0], size=batch_size)\n","        fixed_images = x_data[idx2, ..., np.newaxis]\n","        inputs = [moving_images, fixed_images]\n","        \n","        # prepare outputs (the 'true' moved image):\n","        # of course, we don't have this, but we know we want to compare \n","        # the resulting moved image with the fixed image. \n","        # we also wish to penalize the deformation field. \n","        outputs = [fixed_images, zero_phi]\n","        \n","        yield (inputs, outputs)"],"metadata":{"id":"GLxVoORcqVWl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# let's test it\n","train_generator = vxm_data_generator(x_train)\n","in_sample, out_sample = next(train_generator)\n","\n","# visualize\n","images = [img[0, :, :, 0] for img in in_sample + out_sample] \n","titles = ['moving', 'fixed', 'moved ground-truth (fixed)', 'zeros']\n","ne.plot.slices(images, titles=titles, cmaps=['gray'], do_colorbars=True);"],"metadata":{"id":"ipwG-JnoqmKu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nb_epochs = 10\n","steps_per_epoch = 100\n","hist = vxm_model.fit_generator(train_generator, epochs=nb_epochs, steps_per_epoch=steps_per_epoch, verbose=2);"],"metadata":{"id":"Hr_l2Ls2qsbu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","def plot_history(hist, loss_name='loss'):\n","    # Simple function to plot training history.\n","    plt.figure()\n","    plt.plot(hist.epoch, hist.history[loss_name], '.-')\n","    plt.ylabel('loss')\n","    plt.xlabel('epoch')\n","    plt.show()\n","\n","plot_history(hist)"],"metadata":{"id":"RU7ehIXeqyCf"},"execution_count":null,"outputs":[]}]}